{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Chinese character \"detection\"\n",
    "LT2326, Autumn 2021\n",
    "\n",
    "Name: Max Boholm (gusbohom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook cotains the code for *Assignment 1: Chinese character \"detection\"* for the course *Machine learning for statistical NLP: Advanced* (course code LT2326), Autumn 2021. The notebook is organized into the folowing parts:\n",
    "\n",
    "*    Meta variables (the term *hyperparameter* is here reserved for decisions on the models), which define ... the loacation (path) of the data, ... \n",
    "*    Data preparation\n",
    "*    Definition and training of two models\n",
    "*    Testing and evaluation\n",
    "*    ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"../../scratch/lt2326-h21/a1/\"\n",
    "path = \"../develop_util/\"\n",
    "images_dir = path + \"images\"      # the directory of images to be data\n",
    "meta_ctw   = path + \"info.json\"   # the (path to) the general meta file of CTW \n",
    "meta_train = path + \"train.jsonl\" # the (path to) the file containing the annotations of CTW training data\n",
    "\n",
    "train_proportion = 0.7 # the proportion of training data; proportion of test data will be the complement of this number\n",
    "\n",
    "restriction = None # set to an integer, if subsample of the data is to be used in e.g. the development phase\n",
    "\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = ...\n",
    "lr = ... \n",
    "stride = ...\n",
    "window = ...\n",
    "... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '../develop_util/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-618f1f8bec52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monly_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTW_mapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0mmy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-618f1f8bec52>\u001b[0m in \u001b[0;36mCTW_mapper\u001b[0;34m(files, meta)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mannotations_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '../develop_util/'"
     ]
    }
   ],
   "source": [
    "def only_train(file_dir = images_dir, meta_file = meta_ctw):\n",
    "    \"\"\"Tests whether image files in a directory is part of the training set of the CTW data set, \n",
    "       as defined by the json metafile for CTW. Returns a list of filenames such that they are both\n",
    "       in the specified directory and the CTW training set.\n",
    "    \"\"\"\n",
    "    meta = json.load(open(meta_file,\"r\"))\n",
    "    \n",
    "    train_files_CTW = [entry[\"file_name\"] for entry in meta[\"train\"]]\n",
    "        \n",
    "    files_to_keep = []\n",
    "    \n",
    "    for file in glob.glob(file_dir+\"*.jpg\"):\n",
    "        if file in train_files_CTW:\n",
    "            files_to_keep.append(file)\n",
    "        \n",
    "    return files_to_keep\n",
    "\n",
    "def CTW_mapper(files, meta = meta_train):\n",
    "    \"\"\" Identifies annotations for files from the training set of the CTW dataset. \n",
    "        Returns pyhoton dictionary that maps filenames (keys) with annotations (values), \n",
    "        which like in the original format is a list of lists of json elements / python dictinaries. \n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "   \n",
    "    with open(meta, \"r\") as f:\n",
    "        \n",
    "        annotations_data = f.readlines()\n",
    "\n",
    "        for file in files:\n",
    "            for annotation in annotations_data:\n",
    "                if annotation[\"image_id\"] == file[:-4]:\n",
    "                    mapping[file] = annotations_data[\"annotations\"]\n",
    "                    break\n",
    "    \n",
    "    return mapping\n",
    "                    \n",
    "def img2vector(file, directory=images_dir, device=device):\n",
    "    \"\"\" Takes a filename of an image in a directory and returns a ...\n",
    "    \"\"\"\n",
    "    \n",
    "    img = Image.open(directory+file)\n",
    "    img_vec = torch.LongTensor(np.array(img), device=device) # do I really need this nesting?\n",
    "    \n",
    "    #flatten?\n",
    "    #padding?\n",
    "    \n",
    "    return img_vec\n",
    "\n",
    "def coordinates2vector(file, mapping, device=device, height = 2048, width = 2048): \n",
    "    \"\"\" Builds a vector of 0s and 1s based on the coordinates ...\n",
    "    \"\"\"\n",
    "    \n",
    "    char_matrix = torch.zeros(height, width, device=device)\n",
    "    \n",
    "    char_areas = []\n",
    "    for block in mapping[file]:\n",
    "        for character in block:\n",
    "            if character[\"is_chinese\"] == True:\n",
    "                xmin = character[\"adjusted_bbox\"][0]\n",
    "                ymin = character[\"adjusted_bbox\"][1]\n",
    "                w    = character[\"adjusted_bbox\"][2]\n",
    "                h    = character[\"adjusted_bbox\"][3]\n",
    "                char_areas.append((xmin, ymin, w, h))\n",
    "    \n",
    "    for xmin, ymin, w, h in char_areas:\n",
    "        \n",
    "        r1 = height - ymin - h\n",
    "        r2 = r1 + h\n",
    "        c1 = width - xmin\n",
    "        c2 = c1 + w\n",
    "        \n",
    "        char_matrix[r1:r2 , c1:c2] = 1\n",
    "    \n",
    "    #flatten?\n",
    "    \n",
    "    return char_matrix\n",
    "        \n",
    "def data_builder(files, directory, mapping, restriction = restriction):\n",
    "    \"\"\" Compiles the data set for use. Returns a list of dictionaties, specifying:\n",
    "        -  the filename; key: \"file\"\n",
    "        -  the training data (vector); key: \"img_vector\"\n",
    "        -  the labels (a vector of 0s and 1s indicating boxes of characters in images); key: \"label\" \n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for file in files:\n",
    "        instance = {}\n",
    "        instance[\"file\"] = file\n",
    "        instance[\"img_vector\"] = img2vector(file)\n",
    "        instance[\"label\"] = coordinates2vector(file, mapping)\n",
    "        data.append(d) \n",
    "    \n",
    "    if restriction != None:\n",
    "        random.shuffle(data)\n",
    "        data = data[:restriction]\n",
    "        \n",
    "    return data\n",
    "    \n",
    "files = only_train()\n",
    "mapping = CTW_mapper(files, path)\n",
    "my_data = data_builder(files, images_dir, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split():\n",
    "    pass\n",
    "\n",
    "train_data, test_data = split(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need padding!\n",
    "\n",
    "\n",
    "\n",
    "#to be used in training below ... \n",
    "def data_loader(data, batch):\n",
    "    ...\n",
    "    yield ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t = torch.zeros(10, 10)\n",
    "t[1:3, 5:7]=1 # rows, columns\n",
    "print(t.shape)\n",
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "img = Image.open(\"../develop_util/images/0000172.jpg\")\n",
    "\n",
    "img_np=np.array(img)\n",
    "img_vec=torch.LongTensor(img_np)\n",
    "#print(img)\n",
    "img_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_name = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_name = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: testing and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
